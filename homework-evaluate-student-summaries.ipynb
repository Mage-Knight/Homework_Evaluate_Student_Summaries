{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport gensim\nimport nltk\nimport spacy\nimport re\nimport spacy\nimport matplotlib.pyplot as plt\nimport string\nimport math\n\nfrom ydata_profiling import ProfileReport\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\nfrom nltk import tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LinearRegression, ElasticNet\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom spacy import displacy\nfrom transformers import pipeline\nfrom itertools import product\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T10:16:42.948131Z","iopub.execute_input":"2023-10-01T10:16:42.948548Z","iopub.status.idle":"2023-10-01T10:16:42.959600Z","shell.execute_reply.started":"2023-10-01T10:16:42.948516Z","shell.execute_reply":"2023-10-01T10:16:42.958449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read data","metadata":{}},{"cell_type":"code","source":"prompts_train = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv\")\nprompts_test = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/sample_submission.csv\")\nsummaries_test = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv\")\nsummaries_train = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:16:42.963219Z","iopub.execute_input":"2023-10-01T10:16:42.964000Z","iopub.status.idle":"2023-10-01T10:16:43.102200Z","shell.execute_reply.started":"2023-10-01T10:16:42.963958Z","shell.execute_reply":"2023-10-01T10:16:43.101405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Explore data","metadata":{}},{"cell_type":"code","source":"prompts_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:16:43.104148Z","iopub.execute_input":"2023-10-01T10:16:43.104801Z","iopub.status.idle":"2023-10-01T10:16:43.132004Z","shell.execute_reply.started":"2023-10-01T10:16:43.104763Z","shell.execute_reply":"2023-10-01T10:16:43.130895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompts_train.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:16:43.134025Z","iopub.execute_input":"2023-10-01T10:16:43.135072Z","iopub.status.idle":"2023-10-01T10:16:43.145218Z","shell.execute_reply.started":"2023-10-01T10:16:43.135024Z","shell.execute_reply":"2023-10-01T10:16:43.143818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompts_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:16:43.148784Z","iopub.execute_input":"2023-10-01T10:16:43.149690Z","iopub.status.idle":"2023-10-01T10:16:43.162962Z","shell.execute_reply.started":"2023-10-01T10:16:43.149646Z","shell.execute_reply":"2023-10-01T10:16:43.161862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompts_test.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:16:43.164859Z","iopub.execute_input":"2023-10-01T10:16:43.165540Z","iopub.status.idle":"2023-10-01T10:16:43.178890Z","shell.execute_reply.started":"2023-10-01T10:16:43.165498Z","shell.execute_reply":"2023-10-01T10:16:43.177792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:16:43.180112Z","iopub.execute_input":"2023-10-01T10:16:43.181062Z","iopub.status.idle":"2023-10-01T10:16:43.198681Z","shell.execute_reply.started":"2023-10-01T10:16:43.181023Z","shell.execute_reply":"2023-10-01T10:16:43.197808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:16:43.200299Z","iopub.execute_input":"2023-10-01T10:16:43.200831Z","iopub.status.idle":"2023-10-01T10:16:43.213928Z","shell.execute_reply.started":"2023-10-01T10:16:43.200799Z","shell.execute_reply":"2023-10-01T10:16:43.213055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summaries_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:16:43.216003Z","iopub.execute_input":"2023-10-01T10:16:43.216443Z","iopub.status.idle":"2023-10-01T10:16:43.232437Z","shell.execute_reply.started":"2023-10-01T10:16:43.216403Z","shell.execute_reply":"2023-10-01T10:16:43.231392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summaries_test.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:16:43.234149Z","iopub.execute_input":"2023-10-01T10:16:43.234779Z","iopub.status.idle":"2023-10-01T10:16:43.247810Z","shell.execute_reply.started":"2023-10-01T10:16:43.234748Z","shell.execute_reply":"2023-10-01T10:16:43.246894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summaries_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:16:43.251379Z","iopub.execute_input":"2023-10-01T10:16:43.251780Z","iopub.status.idle":"2023-10-01T10:16:43.264933Z","shell.execute_reply.started":"2023-10-01T10:16:43.251749Z","shell.execute_reply":"2023-10-01T10:16:43.264069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summaries_train.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:16:43.266112Z","iopub.execute_input":"2023-10-01T10:16:43.266525Z","iopub.status.idle":"2023-10-01T10:16:43.278332Z","shell.execute_reply.started":"2023-10-01T10:16:43.266499Z","shell.execute_reply":"2023-10-01T10:16:43.277510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Joining summaries_train and prompts_train on \"prompt_id\"\nmerged_train = pd.merge(summaries_train, prompts_train, on=\"prompt_id\", how=\"inner\")\nmerged_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:16:43.279716Z","iopub.execute_input":"2023-10-01T10:16:43.280288Z","iopub.status.idle":"2023-10-01T10:16:43.324485Z","shell.execute_reply.started":"2023-10-01T10:16:43.280261Z","shell.execute_reply":"2023-10-01T10:16:43.323727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"profile = ProfileReport(merged_train, title=\"Profiling Report\")\nprofile","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:16:43.325866Z","iopub.execute_input":"2023-10-01T10:16:43.326380Z","iopub.status.idle":"2023-10-01T10:17:08.645455Z","shell.execute_reply.started":"2023-10-01T10:16:43.326351Z","shell.execute_reply":"2023-10-01T10:17:08.644044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see vording and content are highly correlated, but this is predictable, because usually, if people write work well, both values will be high\n## Label distribution","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15, 5))\nplt.subplot(121)\nsns.histplot(data=merged_train, x='content')\nplt.subplot(122)\nsns.histplot(data=merged_train, x='wording')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:17:08.647755Z","iopub.execute_input":"2023-10-01T10:17:08.648687Z","iopub.status.idle":"2023-10-01T10:17:09.211495Z","shell.execute_reply.started":"2023-10-01T10:17:08.648629Z","shell.execute_reply":"2023-10-01T10:17:09.210721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess data","metadata":{}},{"cell_type":"code","source":"nltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\n\ndef collapse_dots(input):\n    # Collapse sequential dots\n    input = re.sub(\"\\.+\", \".\", input)\n    # Collapse dots separated by whitespaces\n    all_collapsed = False\n    while not all_collapsed:\n        output = re.sub(r\"\\.(( )*)\\.\", \".\", input)\n        all_collapsed = input == output\n        input = output\n    return output\n\ndef process_text(text):\n    # Check if input is a string\n    if not isinstance(text, str):\n        return text\n\n    # Initialize stopwords, lemmatizer, and punctuation set\n    stop_words = set(stopwords.words('english'))\n\n    # Remove links\n    # text = re.sub(r\"http\\S+\", \"\", text)\n    text = re.sub(r'[\\r\\n]+', \". \", text)\n    # text = text.replace(\"\\r\\n\", \". \")\n    # Remove period occurence with those symbols\n    for symb in [\"!\", \",\", \":\", \";\", \"?\"]:\n        text = re.sub(rf\"\\{symb}\\.\", symb, text)\n    #input = re.sub(\"[^а-яА-Яa-zA-Z0-9!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~ё]+\", \" \", input)\n    text = re.sub(\"[^a-zA-Z0-9!\\’\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~ё]+\", \" \", text)\n    # Remove hashtags\n    text = re.sub(r\"#\\S+\", \"\", text)\n    text = collapse_dots(text)\n    text = text.lower()\n    \n    # # Lemmatize\n    # nlp = spacy.load(\"en_core_web_sm\")\n    # doc = nlp(text)\n    # text = \" \".join([token.lemma_ for token in doc])\n\n    # Remove leading and ending whitespace\n    text = text.strip()\n    return text","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:17:09.212939Z","iopub.execute_input":"2023-10-01T10:17:09.213893Z","iopub.status.idle":"2023-10-01T10:17:09.446040Z","shell.execute_reply.started":"2023-10-01T10:17:09.213864Z","shell.execute_reply":"2023-10-01T10:17:09.445044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_train[\"clean_text\"] = merged_train[\"text\"].apply(process_text)\nmerged_train[\"clean_prompt_text\"] = merged_train[\"prompt_text\"].apply(process_text)\nfor idx in [10, 100 , 150]:\n    print(\n        f\"Before : {merged_train['text'][idx]}\\n\"\n        f\"Light Processing : {merged_train['clean_text'][idx]}\\n\"\n    )","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:17:09.447270Z","iopub.execute_input":"2023-10-01T10:17:09.447534Z","iopub.status.idle":"2023-10-01T10:17:15.974160Z","shell.execute_reply.started":"2023-10-01T10:17:09.447511Z","shell.execute_reply":"2023-10-01T10:17:15.973054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SOURCE: https://www.kaggle.com/code/gusthema/commonlit-evaluate-student-summaries-w-tfdf/notebook\n\n# Count the stop words in the text.\ndef count_stopwords(text: str) -> int:\n    stopword_list = set(stopwords.words('english'))\n    words = text.split()\n    stopwords_count = sum(1 for word in words if word.lower() in stopword_list)\n    return stopwords_count\n\n# Count the punctuations in the text.\n# punctuation_set -> !\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~\ndef count_punctuation(text: str) -> int:\n    punctuation_set = set(string.punctuation)\n    punctuation_count = sum(1 for char in text if char in punctuation_set)\n    return punctuation_count\n\n# Count the digits in the text.\ndef count_numbers(text: str) -> int:\n    numbers = re.findall(r'\\d+', text)\n    numbers_count = len(numbers)\n    return numbers_count\n\n# This function applies all the above preprocessing functions on a text feature.\ndef feature_engineer(dataframe_real: pd.DataFrame, feature: str = 'clean_text') -> pd.DataFrame:\n    dataframe = dataframe_real.copy()\n    dataframe[f'{feature}_word_cnt'] = dataframe[feature].apply(lambda x: len(x.split(' ')))\n    dataframe[f'{feature}_length'] = dataframe[feature].apply(lambda x: len(x))\n    dataframe[f'{feature}_stopword_cnt'] = dataframe[feature].apply(lambda x: count_stopwords(x))\n    dataframe[f'{feature}_punct_cnt'] = dataframe[feature].apply(lambda x: count_punctuation(x))\n    dataframe[f'{feature}_number_cnt'] = dataframe[feature].apply(lambda x: count_numbers(x))\n    return dataframe","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:44:15.567571Z","iopub.execute_input":"2023-10-01T10:44:15.568092Z","iopub.status.idle":"2023-10-01T10:44:15.581567Z","shell.execute_reply.started":"2023-10-01T10:44:15.568049Z","shell.execute_reply":"2023-10-01T10:44:15.580449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_train_stats = feature_engineer(merged_train)\nmerged_train_stats.head()\n# text_length is measured in symbols","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:17:15.986911Z","iopub.execute_input":"2023-10-01T10:17:15.987885Z","iopub.status.idle":"2023-10-01T10:17:17.370567Z","shell.execute_reply.started":"2023-10-01T10:17:15.987856Z","shell.execute_reply":"2023-10-01T10:17:17.369854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_train_stats.describe()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:17:17.379396Z","iopub.execute_input":"2023-10-01T10:17:17.380043Z","iopub.status.idle":"2023-10-01T10:17:17.417049Z","shell.execute_reply.started":"2023-10-01T10:17:17.380016Z","shell.execute_reply":"2023-10-01T10:17:17.416105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_train_stats[\"merged_text\"] = (\n    merged_train_stats[\"prompt_title\"] + \". \" + merged_train_stats[\"prompt_question\"] + \" \" +  merged_train_stats[\"clean_prompt_text\"] + \". \" + merged_train_stats[\"clean_text\"]\n)\n\nmerged_train_stats[\"merged_text\"].iloc[10]","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:17:17.418498Z","iopub.execute_input":"2023-10-01T10:17:17.418791Z","iopub.status.idle":"2023-10-01T10:17:17.529226Z","shell.execute_reply.started":"2023-10-01T10:17:17.418766Z","shell.execute_reply":"2023-10-01T10:17:17.528302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split data into train and validation datasets","metadata":{}},{"cell_type":"code","source":"x_train_content, x_validate_content, y_train_content, y_validate_content = train_test_split(\n    merged_train_stats[\"merged_text\"],\n    merged_train_stats[\"content\"],\n    test_size=0.3,random_state=1\n)\nx_train_wording, x_validate_wording, y_train_wording, y_validate_wording = train_test_split(\n    merged_train_stats[\"merged_text\"],\n    merged_train_stats[\"wording\"],\n    test_size=0.3,random_state=1\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:17:17.531012Z","iopub.execute_input":"2023-10-01T10:17:17.531413Z","iopub.status.idle":"2023-10-01T10:17:17.544661Z","shell.execute_reply.started":"2023-10-01T10:17:17.531376Z","shell.execute_reply":"2023-10-01T10:17:17.543628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Pipeline\nLet's start with simple LinearRegression","metadata":{}},{"cell_type":"code","source":"pipe_regression_content = Pipeline([\n    ('vectorizer', TfidfVectorizer(\n        analyzer='word',\n        strip_accents='ascii',\n        stop_words='english',\n        ngram_range=(1, 3),\n        min_df=5,\n        max_features=30000\n    )),  \n    ('regressor', LinearRegression())\n])\npipe_regression_wording = Pipeline([\n    ('vectorizer', TfidfVectorizer(\n        analyzer='word',\n        strip_accents='ascii',\n        stop_words='english',\n        ngram_range=(1, 3),\n        min_df=5,\n        max_features=30000\n    )),  \n    ('regressor', LinearRegression())\n])\npipe_regression_content.fit(x_train_content, y_train_content)\npipe_regression_wording.fit(x_train_wording, y_train_wording)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:17:17.546169Z","iopub.execute_input":"2023-10-01T10:17:17.546553Z","iopub.status.idle":"2023-10-01T10:18:43.287747Z","shell.execute_reply.started":"2023-10-01T10:17:17.546516Z","shell.execute_reply":"2023-10-01T10:18:43.286973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_train_content = pipe_regression_content.predict(x_train_content)\npredictions_train_wording = pipe_regression_wording.predict(x_train_wording)\npredictions_validate_content = pipe_regression_content.predict(x_validate_content)\npredictions_validate_wording = pipe_regression_wording.predict(x_validate_wording)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:18:43.288958Z","iopub.execute_input":"2023-10-01T10:18:43.289255Z","iopub.status.idle":"2023-10-01T10:18:58.886018Z","shell.execute_reply.started":"2023-10-01T10:18:43.289231Z","shell.execute_reply":"2023-10-01T10:18:58.885172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate","metadata":{}},{"cell_type":"code","source":"def RMSE(actual: np.ndarray, predicted: np.ndarray) -> float:\n    return math.sqrt(((actual-predicted)**2).mean())\n \nprint(f'RMSE Train content: {RMSE(y_train_content, predictions_train_content)}',\n      f'RMSE Validate content: {RMSE(y_validate_content, predictions_validate_content)}')\nprint(f'RMSE Train wording: {RMSE(y_train_wording, predictions_train_wording)}',\n      f'RMSE Validate wording: {RMSE(y_validate_wording, predictions_validate_wording)}')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:18:58.887306Z","iopub.execute_input":"2023-10-01T10:18:58.887694Z","iopub.status.idle":"2023-10-01T10:18:58.896751Z","shell.execute_reply.started":"2023-10-01T10:18:58.887660Z","shell.execute_reply":"2023-10-01T10:18:58.895653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we see, the model is overfitting. Let's try linear regression with reguralization, for example,  sklearn.linear_model.ElasticNet","metadata":{}},{"cell_type":"code","source":"pipe_regression_content_EN = Pipeline([\n    ('vectorizer', TfidfVectorizer(\n        analyzer='word',\n        strip_accents='ascii',\n        stop_words='english',\n        ngram_range=(1, 3),\n        min_df=5,\n        max_features=30000\n    )),  \n    ('regressor', ElasticNet(alpha=0.5))\n])\npipe_regression_wording_EN = Pipeline([\n    ('vectorizer', TfidfVectorizer(\n        analyzer='word',\n        strip_accents='ascii',\n        stop_words='english',\n        ngram_range=(1, 3),\n        min_df=5,\n        max_features=30000\n    )),  \n    ('regressor', ElasticNet(alpha=0.5))\n])\npipe_regression_content_EN.fit(x_train_content, y_train_content)\npipe_regression_wording_EN.fit(x_train_wording, y_train_wording)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:18:58.898478Z","iopub.execute_input":"2023-10-01T10:18:58.898777Z","iopub.status.idle":"2023-10-01T10:19:10.503767Z","shell.execute_reply.started":"2023-10-01T10:18:58.898751Z","shell.execute_reply":"2023-10-01T10:19:10.502649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_train_content_EN = pipe_regression_content_EN.predict(x_train_content)\npredictions_train_wording_EN = pipe_regression_wording_EN.predict(x_train_wording)\npredictions_validate_content_EN = pipe_regression_content_EN.predict(x_validate_content)\npredictions_validate_wording_EN = pipe_regression_wording_EN.predict(x_validate_wording)\nprint(f'RMSE Train content: {RMSE(y_train_content, predictions_train_content_EN)}',\n      f'RMSE Validate content: {RMSE(y_validate_content, predictions_validate_content_EN)}')\nprint(f'RMSE Train wording: {RMSE(y_train_wording, predictions_train_wording_EN)}',\n      f'RMSE Validate wording: {RMSE(y_validate_wording, predictions_validate_wording_EN)}')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:19:10.505313Z","iopub.execute_input":"2023-10-01T10:19:10.506547Z","iopub.status.idle":"2023-10-01T10:19:26.041468Z","shell.execute_reply.started":"2023-10-01T10:19:10.506506Z","shell.execute_reply":"2023-10-01T10:19:26.040389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We get better results for content prediction (and a little bit better for wording prediction). Let's also try Gradient boosting regression tree model:","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:32:08.542232Z","iopub.execute_input":"2023-10-01T06:32:08.542633Z","iopub.status.idle":"2023-10-01T06:32:08.549857Z","shell.execute_reply.started":"2023-10-01T06:32:08.542606Z","shell.execute_reply":"2023-10-01T06:32:08.548340Z"}}},{"cell_type":"code","source":"pipe_regression_content_GBR = Pipeline([\n    ('vectorizer', TfidfVectorizer(\n        analyzer='word',\n        strip_accents='ascii',\n        stop_words='english',\n        ngram_range=(1, 3),\n        min_df=5,\n        max_features=30000\n    )),  \n    ('regressor', GradientBoostingRegressor(random_state=1))\n])\npipe_regression_wording_GBR = Pipeline([\n    ('vectorizer', TfidfVectorizer(\n        analyzer='word',\n        strip_accents='ascii',\n        stop_words='english',\n        ngram_range=(1, 3),\n        min_df=5,\n        max_features=30000\n    )),  \n    ('regressor', GradientBoostingRegressor(random_state=1))\n])\npipe_regression_content_GBR.fit(x_train_content, y_train_content)\npipe_regression_wording_GBR.fit(x_train_wording, y_train_wording)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:19:26.046406Z","iopub.execute_input":"2023-10-01T10:19:26.047257Z","iopub.status.idle":"2023-10-01T10:25:10.586822Z","shell.execute_reply.started":"2023-10-01T10:19:26.047226Z","shell.execute_reply":"2023-10-01T10:25:10.585682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_train_content_GBR = pipe_regression_content_GBR.predict(x_train_content)\npredictions_train_wording_GBR = pipe_regression_wording_GBR.predict(x_train_wording)\npredictions_validate_content_GBR = pipe_regression_content_GBR.predict(x_validate_content)\npredictions_validate_wording_GBR = pipe_regression_wording_GBR.predict(x_validate_wording)\nprint(f'RMSE Train content: {RMSE(y_train_content, predictions_train_content_GBR)}',\n      f'RMSE Validate content: {RMSE(y_validate_content, predictions_validate_content_GBR)}')\nprint(f'RMSE Train wording: {RMSE(y_train_wording, predictions_train_wording_GBR)}',\n      f'RMSE Validate wording: {RMSE(y_validate_wording, predictions_validate_wording_GBR)}')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:25:29.305170Z","iopub.execute_input":"2023-10-01T10:25:29.305628Z","iopub.status.idle":"2023-10-01T10:25:44.929356Z","shell.execute_reply.started":"2023-10-01T10:25:29.305551Z","shell.execute_reply":"2023-10-01T10:25:44.928382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we see we get even better results with GradientBoostingRegressor, but the disadvantage is longer computing time. Let's also try different approach: we will use GradientBoostingRegressor and data obtained from feature_engineer","metadata":{}},{"cell_type":"code","source":"# Features that will be used to predict wording and content: number of words, symbols, stopwords in the text, etc.\nfeatures = merged_train_stats.drop(columns = ['student_id', 'prompt_id', 'text', 'content',\n'wording', 'prompt_question', 'prompt_title', 'prompt_text','clean_text','clean_prompt_text', 'merged_text', 'prompt_question_encoded'], axis = 1).columns.to_list()\nlabel_encoder = LabelEncoder()\n\n# Fit and transform the 'prompt_question' column\n# It is used to track summaries written on different questions\nmerged_train_stats['prompt_question_encoded'] = label_encoder.fit_transform(merged_train_stats['prompt_question'])\nmerged_train_stats.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:27:31.947208Z","iopub.execute_input":"2023-10-01T10:27:31.947574Z","iopub.status.idle":"2023-10-01T10:27:31.967827Z","shell.execute_reply.started":"2023-10-01T10:27:31.947544Z","shell.execute_reply":"2023-10-01T10:27:31.966820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:32:27.156635Z","iopub.execute_input":"2023-10-01T10:32:27.157007Z","iopub.status.idle":"2023-10-01T10:32:27.163449Z","shell.execute_reply.started":"2023-10-01T10:32:27.156979Z","shell.execute_reply":"2023-10-01T10:32:27.162175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features = features.copy()\ntrain_features.append(\"prompt_question_encoded\")\nx_tr_stats_content, x_vld_stats_content, y_tr_stats_content, y_vld_stats_content = train_test_split(\n    merged_train_stats[train_features],\n    merged_train_stats[\"content\"],\n    test_size=0.3,random_state=1\n)\nx_tr_stats_wording, x_vld_stats_wording, y_tr_stats_wording, y_vld_stats_wording = train_test_split(\n    merged_train_stats[train_features],\n    merged_train_stats[\"wording\"],\n    test_size=0.3,random_state=1\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:33:08.659477Z","iopub.execute_input":"2023-10-01T10:33:08.659842Z","iopub.status.idle":"2023-10-01T10:33:08.676241Z","shell.execute_reply.started":"2023-10-01T10:33:08.659812Z","shell.execute_reply":"2023-10-01T10:33:08.675285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe_regression_stats_content_GBR = GradientBoostingRegressor(random_state=1)\npipe_regression_stats_wording_GBR = GradientBoostingRegressor(random_state=1)\npipe_regression_stats_content_GBR.fit(x_tr_stats_content, y_tr_stats_content)\npipe_regression_stats_wording_GBR.fit(x_tr_stats_wording, y_tr_stats_wording)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:33:24.280392Z","iopub.execute_input":"2023-10-01T10:33:24.280756Z","iopub.status.idle":"2023-10-01T10:33:25.150812Z","shell.execute_reply.started":"2023-10-01T10:33:24.280729Z","shell.execute_reply":"2023-10-01T10:33:25.149766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_tr_stats_content_GBR = pipe_regression_stats_content_GBR.predict(x_tr_stats_content)\npredictions_tr_stats_wording_GBR = pipe_regression_stats_wording_GBR.predict(x_tr_stats_wording)\npredictions_vld_stats_content_GBR = pipe_regression_stats_content_GBR.predict(x_vld_stats_content)\npredictions_vld_stats_wording_GBR = pipe_regression_stats_wording_GBR.predict(x_vld_stats_wording)\nprint(f'RMSE Train content: {RMSE(y_tr_stats_content, predictions_tr_stats_content_GBR)}',\n      f'RMSE Validate content: {RMSE(y_vld_stats_content, predictions_vld_stats_content_GBR)}')\nprint(f'RMSE Train wording: {RMSE(y_tr_stats_wording, predictions_tr_stats_wording_GBR)}',\n      f'RMSE Validate wording: {RMSE(y_vld_stats_wording, predictions_vld_stats_wording_GBR)}')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:37:50.606645Z","iopub.execute_input":"2023-10-01T10:37:50.606991Z","iopub.status.idle":"2023-10-01T10:37:50.646293Z","shell.execute_reply.started":"2023-10-01T10:37:50.606966Z","shell.execute_reply":"2023-10-01T10:37:50.645635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This simpler in some sense model provides even better results than the previuos one, which took into account all text. We will use this one for a submission part.","metadata":{}},{"cell_type":"markdown","source":"## Submission part for scoring on kaggle","metadata":{"execution":{"iopub.status.busy":"2023-10-01T08:09:28.242668Z","iopub.execute_input":"2023-10-01T08:09:28.243270Z","iopub.status.idle":"2023-10-01T08:09:28.273731Z","shell.execute_reply.started":"2023-10-01T08:09:28.243239Z","shell.execute_reply":"2023-10-01T08:09:28.272780Z"}}},{"cell_type":"code","source":"merged_test = pd.merge(summaries_test, prompts_test, on=\"prompt_id\", how=\"inner\")\nmerged_test[\"clean_text\"] = merged_test[\"text\"].apply(process_text)\nmerged_test_stats = feature_engineer(merged_test)\nmerged_test_stats['prompt_question_encoded'] = label_encoder.fit_transform(merged_test_stats['prompt_question'])\nmerged_test_stats['content'] = pipe_regression_stats_content_GBR.predict(merged_test_stats[train_features])\nmerged_test_stats['wording'] = pipe_regression_stats_wording_GBR.predict(merged_test_stats[train_features])\nmerged_test_stats.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:57:24.739004Z","iopub.execute_input":"2023-10-01T10:57:24.739358Z","iopub.status.idle":"2023-10-01T10:57:24.769326Z","shell.execute_reply.started":"2023-10-01T10:57:24.739333Z","shell.execute_reply":"2023-10-01T10:57:24.768354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_test_stats[['student_id', 'content', 'wording']].to_csv('submission.csv',index=False)\ndisplay(pd.read_csv('submission.csv'))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:00:22.956551Z","iopub.execute_input":"2023-10-01T11:00:22.956935Z","iopub.status.idle":"2023-10-01T11:00:22.974516Z","shell.execute_reply.started":"2023-10-01T11:00:22.956909Z","shell.execute_reply":"2023-10-01T11:00:22.973372Z"},"trusted":true},"execution_count":null,"outputs":[]}]}